{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T01:20:27.000158Z",
     "start_time": "2019-02-05T01:20:26.994333Z"
    }
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T01:20:32.191768Z",
     "start_time": "2019-02-05T01:20:32.186943Z"
    }
   },
   "source": [
    "See:\n",
    "* [Alexie's 214 notes](https://github.com/alexieleauthaud/ASTR214_2017/blob/master/class9and10_clustering.ipynb)\n",
    "* [Corrfunc, a fast implementation of these algos](https://github.com/manodeep/Corrfunc)\n",
    "* [Appendix A in Zehavi+ 2011](https://iopscience.iop.org/article/10.1088/0004-637X/736/1/59/meta#apj391584app1) talks about the information content of auto vs cross correlation.\n",
    "* [Appendix in Zu+ 2008](https://arxiv.org/abs/0712.3570)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most broadly, what is the probability of finding an object in a volume $dV$ some distance $r$ away from another object? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Point Correlation Function (2pcf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the excess probability (compared to a random distribution) of finding two galaxies separated by a distance $r$. **Excess** is important, else you are also measuring the mean number density $n$. Mathematically,\n",
    "\n",
    "$$\n",
    "dP(r) = n_1 n_2(1 + \\xi(r))dV_1 dV_2\n",
    "$$\n",
    "\n",
    "where $\\xi(r)$ is the correlation function which is unitless and must be $> -1$ (else probability goes negative and we can't have that!). $r$ is the vector pointing from $V_1$ to $V_2$. However, as we assume things are isotropic, only the length of that vector matters.\n",
    "\n",
    "We know that on average the probability of finding a galaxy in a volumne element is $dP = n dV$ and so the probability of finding galaxies in both volume elements is $dP = n_1 dV_1 n_2 dV_2$. Therefore $\\xi(r) > 0$ implies clustering - galaxies are more likely to be separated by that distance than random. $\\xi(r) < 0$ implies anti-clustering.\n",
    "\n",
    "To compute this in practice we setup bins, e.g. $10 < r < 11$Mpc. We then count the number of pairs that are separated by a length that fits in that bin. If we are working in a simulation we can then use the known $n$ and volume to compare this count to the expected one. However, in observations with complex selection effects (redshift dependences, masks, collisions, etc) a carefully constructed random catalog should be used to find the expected number of pairs with this separation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T01:52:53.609732Z",
     "start_time": "2019-02-05T01:52:53.606800Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Auto vs Cross correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Which objects are we measuring the clustering of? There are two options:\n",
    "* Auto correlation: Select a sample of objects (e.g. galaxies with stellar mass between $10^{11}$ and $10^{11.1}$) and find the excess probability of finding members of this sample at a distance $r$ away from other members of it.\n",
    "* Cross correlation: Select two samples of objects (e.g. galaxies with stellar mass between $10^{11}$ and $10^{11.1}$ (sample 1) and ones between $10^{11.1}$ and $10^{11.2}$ (sample 2)) and find the excess probability of finding members of sample 2 at a distance $r$ from sample 1. Note that the order of these doesn't matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d vs 3d correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you don't have redshifts, you only have angular (RA, Dec) positions on the sky. You can still define a 2d angular correlation function,\n",
    "\n",
    "$$\n",
    "dP = n_1 n_2 (1 + \\omega(\\theta))dA_1 dA_2\n",
    "$$\n",
    "\n",
    "where $n$ is now the projected mean number density and $\\omega(\\theta)$ is the angular correlation function.\n",
    "\n",
    "There are many other correlation functions we can build. If we define:\n",
    "* $r$: Separation in real space\n",
    "* $s$: Separation in redshift space\n",
    "* $r_p$: Redshift space separation perpendicular to the LOS \n",
    "* $r_{\\pi}$: Redshift space separation along the LOS \n",
    "* $\\theta$: Angular separation\n",
    "\n",
    "We can have:\n",
    "* $\\xi(r)$: Real space 3d correlation function\n",
    "* $\\xi(s)$: Redshift space 3d correlation function. Sometimes called $\\xi(r_p, r_{\\pi})$\n",
    "* $\\omega_p(r_p)$: Correlation as a function of perpendicular separation (projected)\n",
    "* $\\omega(\\theta)$: The angular version of $\\omega_p(r_p)$, not using redshift to get distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's say we have a simulation. We can compute the correlation function (let's say a $\\xi(r)$ autocorrelation) in various $r$ bins and with various samples (let's say $n$ mass bins). What are the uncertainties on these estimates? What are the covariances between them?\n",
    "\n",
    "The best way to compute this is by using a jackknife. Divide the simulation into say 100 roughly equal sized regions and compute the correlation function 100 times, each time leaving out one of these regions. Do this for all bins of $r$ and $m$ using the same regions. You can now build a covariance matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So far, we've talked about the correlation function being an excess in probability. But how do we actually compute this?\n",
    "\n",
    "We can count the number of galaxies separated by a certain distance bin ($r_1 < r < r_2$). Let's say we are doing a cross correlation between two samples, $s_1$ and $s_2$. We call the number of data pairs in our bin DD.\n",
    "If we are in a simulation, which has a very simple geometry, we can easily compute $\\xi(r)$ from this. The expected number of pairs is just a function of $V_{bin} = 4/3 \\pi (r_2^3 - r_1^3)$, $V_{sim}$, and the number of items in the two samples $ls_1$, $ls_2$.\n",
    "\n",
    "$$\n",
    "n_{exp} = \\frac{V_{bin}  ls_1  ls_2}{V_{sim}}\n",
    "$$\n",
    "\n",
    "However, in observations we typically cannot easily calculate the volume. There are masks (e.g. bright star) and the depth might not be uniform. To get around this, we use a random catalog. Assuming we have two of these ($r_1$, $R_2$) with lengths ($lr_1$, $lr_2$, these should usually be much larger than $ls_{1,2}$ to minimize errors) we can compute,\n",
    "\n",
    "$$\n",
    "n_{exp} = RR \\frac{ls_1 ls_2}{lr_1 lr_2}\n",
    "$$\n",
    "\n",
    "Note that $n_{exp}$ is just $n_1 n_2 dV_1 dV_2$ and so once we have this it is easy to get to $\\xi$:\n",
    "\n",
    "$$\n",
    "1 + \\xi(r) = \\frac{DD}{n_{exp}}\n",
    "$$\n",
    "\n",
    "Some examples,\n",
    "* $DD = 0 \\rightarrow \\xi(r) = -1$. Totally negatively unclustered\n",
    "* $DD = RR \\rightarrow \\xi(r) = 0$. Same clustering as the randoms\n",
    "* $DD = 2RR \\rightarrow \\xi(r) = 1$. A bit more clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It turns out, for reasons I won't go into, that this is not the best possible estimator. We can improve on this slightly by instead using (properly normalized):\n",
    "\n",
    "$$\n",
    "\\xi(r) = \\frac{DD - 2DR + RR}{RR}\n",
    "$$\n",
    "\n",
    "Note how there is no $1 + \\xi(r)$. I don't think this is clearly spelled out in the LS paper, but see equation 47 and note the `+ 2` at the end of the final estimator. We've added 1 to both sides to get the $1 + \\xi(r)$ in this estimator.\n",
    "\n",
    "We can persuade ourselves that the 1 doesn't need to be there by considering unclustered data. In that case $DD - 2DR + RR = n - 2n + n = 0$ which is what we expect for $\\xi(r)$.\n",
    "\n",
    "In full, with the normalization, where we define $f_1 = \\frac{lr_1}{ls_1}$ and similarly for $s_2$,\n",
    "\n",
    "$$\n",
    "\\xi(r) = \\frac{f_1 f_2 DD - f_1 DR - f_2 RD + RR}{RR}\n",
    "$$\n",
    "\n",
    "This is the [Landay-Szalay estimator](http://adsabs.harvard.edu/doi/10.1086/172900)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to be a bit careful with the normalization. When doing a cross-correlation, it is exactly as I have shown above. However, when doing an autocorrelation, things are slightly different. Because self matches are not possible in an autocorrelation there needs to be some $n - 1$ in places.\n",
    "\n",
    "\n",
    "$$\n",
    "\\xi(r) = \\frac{\\frac{lr (lr - 1)}{ls (ls - 1)} DD - 2 DR \\frac{lr}{ls - 1} + RR}{RR}\n",
    "$$\n",
    "\n",
    "See Equation 3 in the LS paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total information content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a population of galaxies A(ll) that we divide into two populations, B(lue) and R(ed). We can compute 5 correlation functions from these populations: AA, BB, RR, BR, RB. Do all of these contain independent information?\n",
    "\n",
    "What is the probability that we find *any* pair at a given separation? Somewhat trivially, it must just be the sum of the probabilities of finding each of the 4 types of pairs that it could be.\n",
    "\n",
    "$$\n",
    "dP_{AA} = dP_{BB} + dP_{RR} + dP_{BR} + dP_{RB}\n",
    "$$\n",
    "\n",
    "Of course, $dP_{BR} = dP_{RB}$ and so,\n",
    "\n",
    "$$\n",
    "dP_A = dP_B + dP_{RR} + 2 dP_{BR}\n",
    "$$\n",
    "\n",
    "Therefore in terms of $\\xi$,\n",
    "\n",
    "$$\n",
    "n_A^2(1 + \\xi_{AA}) = n_B^2 (1 + \\xi_{BB}) + n_R^2 (1 + \\xi_{RR}) + 2 n_B n_R (1 + \\xi_{BR})\n",
    "$$\n",
    "\n",
    "but, $n_A^2 = (n_B + n_R)^2 = n_B^2 + n_R^2 + 2 n_B n_R$ and so subtracting this from both sides,\n",
    "\n",
    "$$\n",
    "n_A^2 \\xi_{AA} = n_B^2 \\xi_{BB} + n_R^2 \\xi_{RR} + 2 n_B n_R \\xi_{BR}\n",
    "$$\n",
    "\n",
    "And therefore given just 3 of these we can determine the fourth.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
